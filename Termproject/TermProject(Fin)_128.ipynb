{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256dc4a2-998b-4d63-9fb6-2edd4a93aece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /usr/local/lib/python3.8/dist-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from opendatasets) (4.64.1)\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (from opendatasets) (1.5.13)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from opendatasets) (8.1.3)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from kaggle->opendatasets) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle->opendatasets) (1.14.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle->opendatasets) (2019.11.28)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7466145f-c79f-46c1-8cf4-9830de19f3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  hyeongchanim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pythonquestions.zip to ./pythonquestions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 558M/558M [00:40<00:00, 14.5MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'https://www.kaggle.com/datasets/stackoverflow/pythonquestions'\n",
    "od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31fd3ea-55bb-4816-8c35-2367461056dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.3.23-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.10.7-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.23.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Installing collected packages: tokenizers, regex, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.10.7 huggingface-hub-0.13.3 regex-2023.3.23 tokenizers-0.13.2 transformers-4.27.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e7fad-0e00-479e-9f2c-9b802f3ded41",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* CSV 파일을 Pandas DataFrame으로 로드합니다.\n",
    "* 질문과 답변을 합쳐서 하나의 문서로 만듭니다.\n",
    "* 문서를 전처리합니다. 예를 들어, HTML 태그나 코드 블록을 제거하거나 소문자로 변환합니다.\n",
    "* 문서를 토큰화합니다. 예를 들어, 문장부호나 공백을 기준으로 문장을 나누고 단어를 추출합니다.\n",
    "* 불용어를 제거합니다. 즉, 자주 등장하지만 의미를 가지지 않는 단어를 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61c3b65-faae-46b1-acf4-f405eb405c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일을 Pandas DataFrame으로 load\n",
    "questions_df = pd.read_csv(\"./pythonquestions/Questions.csv\", encoding='latin1')\n",
    "answers_df = pd.read_csv(\"./pythonquestions/Answers.csv\", encoding='latin1')\n",
    "tags_df = pd.read_csv(\"./pythonquestions/Tags.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6202eaa8-19ca-44eb-ab33-8f6b3b336f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nquestions_df 데이터프레임의 Title과 Body 컬럼을 합쳐서 질문을 만들고, \\n해당 질문에 대한 답변을 answers_df 데이터프레임에서 찾아서 합친다.\\n이렇게 만들어진 문서는 docs 리스트에 추가한다.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문과 답변을 합쳐서 하나의 문서로 만듭니다.\n",
    "docs = []\n",
    "for index, row in questions_df.iterrows():\n",
    "    question = row[\"Title\"] + \" \" + row[\"Body\"]\n",
    "    answer = answers_df.loc[answers_df[\"ParentId\"] == row[\"Id\"], \"Body\"].values\n",
    "    if len(answer) > 0:\n",
    "        answer = answer[0]\n",
    "        doc = question + \" \" + answer\n",
    "        docs.append(doc)\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "questions_df 데이터프레임의 Title과 Body 컬럼을 합쳐서 질문을 만들고, \n",
    "해당 질문에 대한 답변을 answers_df 데이터프레임에서 찾아서 합친다.\n",
    "이렇게 만들어진 문서는 docs 리스트에 추가한다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c23acd-8e29-4892-8195-7e843416f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  # punkt 모듈 다운\n",
    "nltk.download('wordnet') # wordnet 모듈 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f97e3d79-3249-4ab9-ac2a-0c55b2bc3754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "문서 전처리\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# 문서를 전처리합니다.\n",
    "def preprocess_doc(doc):\n",
    "    # HTML 태그를 제거합니다.\n",
    "    doc = re.sub('<[^>]*>', '', doc)\n",
    "\n",
    "    # 코드 블록을 제거합니다.\n",
    "    doc = re.sub('```\\w*\\n([\\s\\S]*?)```', '', doc)\n",
    "\n",
    "    # 소문자로 변환합니다.\n",
    "    doc = doc.lower()\n",
    "\n",
    "    # 문장부호를 제거합니다.\n",
    "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # 단어를 토큰화합니다.\n",
    "    words = word_tokenize(doc)\n",
    "\n",
    "    # 불용어를 제거합니다.\n",
    "    # 불용어란 문장에서 자주사용되나 의미분석에 영향X\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "\n",
    "    # 단어를 원형으로 변환합니다.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "\n",
    "    # 단어를 공백으로 구분하여 문서로 만듭니다.\n",
    "    doc = ' '.join(words)\n",
    "\n",
    "    return doc\n",
    "\n",
    "\n",
    "# 모든 문서를 전처리합니다.\n",
    "preprocessed_docs = []\n",
    "for doc in docs:\n",
    "    preprocessed_doc = preprocess_doc(doc)\n",
    "    preprocessed_docs.append(preprocessed_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c78df-88ab-4e8d-848a-521e6916bb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0b68385-4915-4945-b98a-845cb3a54154",
   "metadata": {},
   "source": [
    "## Model Architecture Compose\n",
    "* 모델 아키텍처는 Transformer 기반의 언어 모델을 사용\n",
    "* Huggingface의 GPT-2 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26aa23-8c45-47b6-9d74-529862f420fc",
   "metadata": {},
   "source": [
    "Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00897e1a-5298-487a-bc66-d7355cd3d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# GPU가 사용 가능한지 확인합니다.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "656673d4-37b9-4a9f-a188-5df3f1d21165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set으로 사용할 텍스트 파일을 생성합니다.\n",
    "with open('trainset.txt', 'w', encoding='utf-8') as f:\n",
    "    for doc in doc:\n",
    "        f.write(doc + '\\n')\n",
    "\n",
    "# trainset 파일을 불러와서 TextDataset과 DataCollatorForLanguageModeling을 사용하여 train set을 처리합니다.\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path='./trainset.txt',\n",
    "    block_size=block_size,\n",
    ")\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90972cbe-48f0-4720-ac35-6959bb1177fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 tokenizer를 load합니다.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# max_length, block_size(GPU 메모리에 맞춰서)를 설정합니다.\n",
    "max_length = 128\n",
    "block_size = 128\n",
    "\n",
    "# 전처리된 문서를 tokenizing합니다.\n",
    "tokenized_docs = [tokenizer(doc, max_length=max_length, truncation=True) for doc in preprocessed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0c54360-6110-4c21-ab6f-c9181922983f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TextDataset과 DataCollatorForLanguageModeling을 사용하여 train set을 처리합니다.\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "file_path = \"./trainset.txt\"  # train set의 파일 경로를 지정해 주세요\n",
    "dataset = TextDataset(file_path=file_path, tokenizer=tokenizer, block_size=block_size)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "\n",
    "\n",
    "# 모델을 load합니다.\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# GPU로 모델을 옮겨줍니다.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba4e44a2-63da-48cc-8da5-01500c51ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments를 설정합니다.\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=500,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    save_steps=10_000,              # number of updates steps between two checkpoints\n",
    "    save_total_limit=2,             # limit the total amount of checkpoints, delete the oldest checkpoints\n",
    "    prediction_loss_only=True,      # only compute loss for masked tokens\n",
    "    learning_rate=2e-5,             # learning rate for optimizer\n",
    "    warmup_steps=500,               # number of warmup steps for learning rate scheduler\n",
    "    gradient_accumulation_steps=16, # number of updates steps to accumulate before performing a backward/update pass\n",
    "    weight_decay=0.01,              # strength of weight decay\n",
    "    logging_dir='./logs',           # directory for storing logs\n",
    "    logging_steps=10_000,           # log & save weights every logging_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbcad7ec-00e6-4cb8-b8ab-429c1cf5b0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:02, Epoch 500/500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.004153316497802735, metrics={'train_runtime': 62.6332, 'train_samples_per_second': 79.83, 'train_steps_per_second': 7.983, 'total_flos': 326615040000000.0, 'train_loss': 0.004153316497802735, 'epoch': 500.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainer 객체를 생성하고 학습을 시작합니다.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888d8ce-8342-456c-a67e-d312f0057824",
   "metadata": {},
   "source": [
    "## 모델 평가 및 예측수행\n",
    "* 모델 저장 후 모델에 대한 예측수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83b36d5c-77cb-4333-849a-e358b1d30806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save_pretrained('./saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba9e8c-b9aa-4cfe-9c75-0418e2b66958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d8af8ac-13bd-49f8-aad1-1b26d5218f89",
   "metadata": {},
   "source": [
    "# Model 작동시켜보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ce7fe-8faf-415a-84c6-76cc8940dc00",
   "metadata": {},
   "source": [
    "1. 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1b26f9f-6d9b-4a8a-9f11-82f9ba6dfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('./saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f8381a-85a4-4c44-8168-50b9a6302105",
   "metadata": {},
   "source": [
    "2. 모델을 사용하여 원하는 문장에 대한 답변을 생성하는 코드를 작성합니다. \n",
    "* 이때 generate 메소드를 사용합니다. generate 메소드는 생성할 문장의 길이와 다양한 설정 등을 인자로 받습니다. \n",
    "* 예를 들어, 아래 코드에서는 generate 메소드의 인자로 prompt와 max_length를 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa13f6-86b5-4391-b052-a24707b3363b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b91adcbe-b718-4409-a017-98f82a7b2079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Enter a question (or 'Quit' to exit):  What is the python?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the python?\n",
      "\n",
      "The python is a project of Python programming language (PL) that was developed by the team of Rob Cordain, who has been working on Python since 2003. The project has since grown to be a top-notch software development platform for Python developers and is used by more than 100,000 users worldwide.\n",
      "\n",
      "The python is a python that is based on the Python programming language. It is based on the framework of the Jupyter notebook, which is a Python-based data type system. It is based on the python-2.5 module, which was released in the latest version of Python 3.6. The python is an open-source project. The project uses a mix of Python libraries to implement various features such as data structures, user interface, and more.\n",
      "\n",
      "What is the python interpreter?\n",
      "\n",
      "The python interpreter is a Python programming language. The python interpreter is a Python object-oriented programming language (ODL). The python interpreter is based on the Python programming language and is used by over 400,000 users worldwide.\n",
      "\n",
      "What is the python interpreter is a language that makes it possible to write Python code, the python interpreter is used for many different reasons. The python interpreter is used for:\n",
      "\n",
      "Python scripting\n",
      "\n",
      "Python software development\n",
      "\n",
      "Python development\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python programming languages\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python code analysis\n",
      "\n",
      "Python codeR\n",
      "\n",
      "The Python R module is a Python object-oriented programming language (ODL\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Enter a question (or 'Quit' to exit):  How can I install python3 in linux environment?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I install python3 in linux environment?\n",
      "\n",
      "python3 is a Python 3 implementation of the user interface. The user interface is a simple GUI that is similar to the standard user interface used by web browsers. It includes buttons, menus, a list, a help menu, a search box, and more. The user interface also includes a button for entering and leaving the screen.\n",
      "\n",
      "Can I use python3 in windows?\n",
      "\n",
      "Yes, using python3 will make it easier to install python3 in windows. You will need to have the following packages installed:\n",
      "\n",
      "python3-dev\n",
      "\n",
      "python3-dev-x86_64\n",
      "\n",
      "python3-dev-x86_64-linux speaking\n",
      "\n",
      "python3-dev-x86_64-win32 speaking\n",
      "\n",
      "python3-dev-x86_64-win32-linux speaking\n",
      "\n",
      "Python 3.2\n",
      "\n",
      "Python 3.2 is the latest version of the Python framework, available for the first time in the release notes. This release includes a new interface that can be used with the latest version of Python 3.2. This new interface has been built on top of the current Python 3.0.0 codebase, and is the latest version of the Python 3.2 compiler.\n",
      "\n",
      "How do I install python3 in windows?\n",
      "\n",
      "Download the latest version of python3 from http://python3.org/download.\n",
      "\n",
      "You can install the python3-dev package with the following command:\n",
      "\n",
      "$ python3 install python3\n",
      "\n",
      "If you are using a Windows system, you will need to install the Python 3.0.0-SNAPSHOT package:\n",
      "\n",
      "$ pip install python3-dev\n",
      "\n",
      "If you are using Linux, you will need to install the python3-x86_64 package:\n",
      "\n",
      "$ pip install python3-x86_64-linux\n",
      "\n",
      "If you are using Windows, you will need to install the python3-x86_64-win32 package:\n",
      "\n",
      "$ pip install python3-x86_64-win32-linux\n",
      "\n",
      "If you are using Mac OS X, you will need to install the python3-x86_64-win32 package:\n",
      "\n",
      "$ pip install python3-x86_64-win32-linux\n",
      "\n",
      "If you are using Linux, you will need to install the python3-x86_64-win32 package:\n",
      "\n",
      "$ pip install python\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Enter a question (or 'Quit' to exit):  What is the difference between list and tuple?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the difference between list and tuple?\n",
      "\n",
      "List and tuple are two different concepts that are completely different concepts. List and tuple are a more complex way of thinking about lists and tuples. For example, consider the following example:\n",
      "\n",
      "class Foo { public: Foo(int i); };\n",
      "\n",
      "The above example defines a Foo class that has a Foo. In the example below, the Foo object is a member of Foo. The definition of Foo.Literal does not include the fact that the Foo is a literal. The definition of Foo.Literal is used to represent the type of the object. In this case, the definition of Foo.Literal is:\n",
      "\n",
      "// Foo.Literal is a literal public: Foo(int i); // Foo.Literal is a literal public: Foo(int i);\n",
      "\n",
      "The definition of Foo.Literal is:\n",
      "\n",
      "// Foo.Literal is a literal\n",
      "\n",
      "What are the differences between tuple and list?\n",
      "\n",
      "List and tuple are a more complex way of thinking about lists and tuples. For example, consider the following example:\n",
      "\n",
      "class Foo { public: Foo(int i); };\n",
      "\n",
      "The above example defines a Foo class that has a Foo. In the example below, the Foo object is a member of Foo. The definition of Foo.Literal does not include the fact that the Foo is a literal. The definition of Foo.Literal is used to represent the type of the object. In this case, the definition of Foo.Literal is:\n",
      "\n",
      "// Foo.Literal is a literal\n",
      "\n",
      "What is the difference between list and tuple?\n",
      "\n",
      "List and tuple are two different concepts that are completely different concepts. List and tuple are a more complex way of thinking about lists and tuples. For example, consider the following example:\n",
      "\n",
      "class Foo { public: Foo(int i); };\n",
      "\n",
      "The above example defines a Foo class that has a Foo. In the example below, the Foo object is a member of Foo. The definition of Foo.Literal does not include the fact that the Foo is a literal. The definition of Foo.Literal is used to represent the type of the object. In this case, the definition of Foo.Literal is:\n",
      "\n",
      "// Foo.Literal is a literal\n",
      "\n",
      "What is the difference between list and tuple?\n",
      "\n",
      "List and tuple are two different\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Enter a question (or 'Quit' to exit):  How to use dictionary and set in python3?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to use dictionary and set in python3?\n",
      "\n",
      "First we need to define dictionary.py for our dictionary. Then we need to create a dictionary.py file asthma.txt and save it to /etc/python3/dict.py.\n",
      "\n",
      "import dict import time def __init__ ( self ): # create our dictionary self. dictionary. set_dict ( self. dict ) def __init__ ( self, age ): # set the age of the dictionary self. age = age self. set_dict ( dict ) def get_dict ( self ): # get the dictionary from dictionary self. __dict__ = dict def get_dict ( self ): # get the dictionary from the specified age self. age = age self. set_dict ( dict ) def get_dict ( self ): # get the dictionary from the specified age self. age = age\n",
      "\n",
      "Once the dictionary is created, we can start writing the dictionary.py file.\n",
      "\n",
      "def _dict_file ( self ): \"\"\" Get dictionary from the specified age \"\"\" def __init__ ( self ): \"\"\" Create the dictionary \"\"\" def get_dict ( self ): \"\"\" Get the dictionary from the specified age \"\"\" self. age = age self. set_dict ( dict ) def get_dict ( self rays = None ): # check if the given ray is a ray def get_ray ( self ): # check if the given ray is a ray def get_ray_type ( self ): # check if the given ray type is a ray def get_ray_version ( self ): # check if the given ray version is a ray def get_ray_length ( self ): # check if the given ray length is a ray def get_ray_type_length ( self ): # check if the given ray type is a ray def get_ashington_type ( self ): # check if the given ray type is a ray def get_salary_type ( self ): # check if the given ray type is a ray def get_salary_type_length ( self ): # check if the given ray type is a ray def get_salary_type_length ( self ): # check if the given ray type is a ray def get_salary_type_length ( self ): # check if the given ray type is a ray def get_salary_type_length ( self ): # check if the given ray type is a ray def get_salary_type_length ( self ): # check if the given ray\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Enter a question (or 'Quit' to exit):  Quit\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"\\n Enter a question (or 'Quit' to exit): \")\n",
    "    if prompt == 'Quit':\n",
    "        break\n",
    "\n",
    "    encoded_prompt = tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=encoded_prompt,\n",
    "        max_length=512,\n",
    "        temperature=0.7,\n",
    "        top_k=0,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.0,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "    generated_sequence = output_sequences[0].tolist()\n",
    "    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54425fb0-88f7-4601-b278-78dafe1f144e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

